<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Advanced Voice</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Geist:wght@100..900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
  <style>
    * {
      font-family: 'Poppins', sans-serif;
    }
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
    }

    #shaderCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100svh;
      z-index: -1;
    }

    #ui {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      color: white;
      text-align: center;
      z-index: 1;
    }
    
    #ui h1 {
      font-size: calc(10vw - 16px);
      margin: 0px;
    }
  </style>
</head>
<body>
  <canvas id="shaderCanvas"></canvas>
  <div id="ui">
    <h1>Advanced Voice</h1>
    <p>Press and hold the spacebar to speak. The AI will respond to your speech.</p>
  </div>

  <audio id="ambientMusic" loop>
    <source src="{{ url_for('static', filename='ambient-music.mp3') }}" type="audio/mp3">
    Your browser does not support the audio element.
  </audio>

  <script>
    let audioPlayed = false;

    document.addEventListener('click', () => {
      if (!audioPlayed) {
        const audio = document.getElementById('ambientMusic');
		audio.volume = 0.5;
        audio.play();
        audioPlayed = true;
      }
    });
	
    let audioContext, mediaRecorder, audioChunks = [];
    let isRecording = false;

    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = audioContext || new AudioContext();
      const input = audioContext.createMediaStreamSource(stream);

      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];

      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: 'audio/wav' });
        const formData = new FormData();
        formData.append('audio', blob, 'input.wav');

        const response = await fetch('/process_audio', {
          method: 'POST',
          body: formData,
        });

        const data = await response.json();
        if (data.audio_url) {
          const audio = new Audio(data.audio_url);
          audio.play();
        }
      };

      mediaRecorder.start();
    }

    function stopRecording() {
      if (mediaRecorder) {
        mediaRecorder.stop();
        audioContext.close();
        audioContext = null;
      }
    }

    document.addEventListener('keydown', (e) => {
      if (e.key === " " && !isRecording) {
        e.preventDefault();
        isRecording = true;
        startRecording();
      }
    });

    document.addEventListener('keyup', (e) => {
      if (e.key === " " && isRecording) {
        e.preventDefault();
        isRecording = false;
        stopRecording();
      }
    });

    // WebGL shader code
    const vertexShaderSource = `#version 300 es
      in vec4 a_position;
      void main() {
        gl_Position = a_position;
      }
    `;

    const fragmentShaderSource = `#version 300 es
      precision highp float;
      out vec4 outColor;
      uniform vec2 u_resolution;
      uniform float u_time;

      vec3 hsv(float h, float s, float v) {
        vec4 t = vec4(1., 2./3., 1./3., 3.);
        vec3 p = abs(fract(vec3(h) + t.xyz) * 6. - t.www);
        return v * mix(vec3(1.0), clamp(p - vec3(1.0), 0.0, 1.0), s);
      }

      mat2 rotate2D(float angle) {
        float c = cos(angle);
        float s = sin(angle);
        return mat2(c, -s, s, c);
      }

      void main() {
        vec2 r = u_resolution;
        vec2 FC = gl_FragCoord.xy;
        float t = u_time;
        vec4 o = vec4(0, 0, 0, 1);

        for (float i, g, e, s; ++i < 99.; o.rgb += hsv(s / 99., .8 * g, e / 8e2)) {
          vec3 p = vec3((FC.xy - 0.5 * r) / r.y * 0.8 + vec2(0, .45), g - 2. + cos(t * .6));
          p.xz *= rotate2D(t * .3);
          s = 11.;
          for (int j = 0; j++ < 9; p = vec3(1.5, 4, 2.5) - abs(abs(p) * e - vec3(6, 4, 3))) {
            s *= e = 6.2 / dot(p, p);
          }
          g += 9e-4 + p.y / s;
          s = log(s);
        }

        outColor = o;
      }
    `;

    function createShader(gl, type, source) {
      const shader = gl.createShader(type);
      gl.shaderSource(shader, source);
      gl.compileShader(shader);
      if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        console.error(gl.getShaderInfoLog(shader));
        gl.deleteShader(shader);
        return null;
      }
      return shader;
    }

    function createProgram(gl, vertexShader, fragmentShader) {
      const program = gl.createProgram();
      gl.attachShader(program, vertexShader);
      gl.attachShader(program, fragmentShader);
      gl.linkProgram(program);
      if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error(gl.getProgramInfoLog(program));
        gl.deleteProgram(program);
        return null;
      }
      return program;
    }

    function main() {
      const canvas = document.getElementById("shaderCanvas");
      const gl = canvas.getContext("webgl2");
      if (!gl) {
        console.error("WebGL 2 is not available.");
        return;
      }

      const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
      const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
      const program = createProgram(gl, vertexShader, fragmentShader);

      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
        -1, -1, 1, -1, -1, 1,
        -1, 1, 1, -1, 1, 1
      ]), gl.STATIC_DRAW);

      const positionAttributeLocation = gl.getAttribLocation(program, "a_position");
      const resolutionUniformLocation = gl.getUniformLocation(program, "u_resolution");
      const timeUniformLocation = gl.getUniformLocation(program, "u_time");

      gl.useProgram(program);
      gl.enableVertexAttribArray(positionAttributeLocation);
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.vertexAttribPointer(positionAttributeLocation, 2, gl.FLOAT, false, 0, 0);

      function render(time) {
        time *= 0.001;
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;
        gl.viewport(0, 0, canvas.width, canvas.height);

        gl.clearColor(0, 0, 0, 1);
        gl.clear(gl.COLOR_BUFFER_BIT);

        gl.uniform2f(resolutionUniformLocation, canvas.width, canvas.height);
        gl.uniform1f(timeUniformLocation, time);

        gl.drawArrays(gl.TRIANGLES, 0, 6);
        requestAnimationFrame(render);
      }

      requestAnimationFrame(render);
    }

    main();
  </script>
</body>
</html>